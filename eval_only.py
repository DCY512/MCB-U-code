#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹è¯„ä¼°è„šæœ¬ (æœ€ç»ˆç‰ˆ v1.1)

åŠŸèƒ½:
- åŠ è½½ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹æ£€æŸ¥ç‚¹ (.pth æ–‡ä»¶)ã€‚
- æ™ºèƒ½åœ°ä»æ£€æŸ¥ç‚¹ä¸­æ¢å¤è®­ç»ƒæ—¶çš„æ¨¡å‹é…ç½® (fuse_mode, head_type, attention_type ç­‰)ã€‚
- è®¡ç®—å¹¶æ‰“å°æ¨¡å‹çš„æ€»å‚æ•°é‡å’Œå¯è®­ç»ƒå‚æ•°é‡ã€‚
- åœ¨éªŒè¯é›†ä¸Šè¿è¡Œè¯„ä¼°ï¼Œè¾“å‡º mAP, per-class AP, F1-micro, F1-macro ç­‰æ ¸å¿ƒæŒ‡æ ‡ã€‚
- å¯é€‰åœ°å°†åŒ…å«æ‰€æœ‰å…³é”®ä¿¡æ¯çš„æ€»ç»“æ€§ç»“æœè¿½åŠ åˆ°ä¸€ä¸ªCSVæ–‡ä»¶ä¸­ï¼Œä¾¿äºæ¨ªå‘æ¯”è¾ƒã€‚


python eval_only.py ^
  --checkpoint ./output_git/95.16_teacher_v2b384_xattn_fpn_fuse_bs16_git_Xattn_C345_fpn_teacher/checkpoint_best.pth ^
  --val_list ./annotations/DvXray_all.txt ^
  --output_csv ./out_csv/evaluation_teacher_v2b384_xattn_fpn_fuse_git_Xattn_C345.csv
"""
import argparse
import torch
from pathlib import Path
import sys
import csv
import os

# ç¡®ä¿è„šæœ¬å¯ä»¥æ‰¾åˆ°é¡¹ç›®ä¸­çš„å…¶ä»–æ¨¡å—
# (å¦‚æœ evaluate_model.py ä¸ main_finetune.py åœ¨åŒä¸€ç›®å½•ï¼Œè¿™é€šå¸¸æ˜¯å¯é€‰çš„)
sys.path.append(str(Path(__file__).parent))

# --- ä»æ‚¨çš„é¡¹ç›®ä¸­å¤ç”¨å…³é”®æ¨¡å— ---
# å¤ç”¨æ¨¡å‹æ„å»ºé€»è¾‘
from main_finetune import build_model
# å¤ç”¨æ•°æ®åŠ è½½é€»è¾‘
from datasets import build_loaders
# å¤ç”¨è¯„ä¼°å¾ªç¯å’ŒæŒ‡æ ‡è®¡ç®—é€»è¾‘
from engine_finetune import evaluate
# å¤ç”¨EMAæ¨¡å‹ï¼Œä»¥è¯„ä¼°æ•™å¸ˆæ¨¡å‹çš„æœ€ç»ˆçŠ¶æ€
from engine_finetune import SimpleEMA

def count_parameters(model: torch.nn.Module):
    """è®¡ç®—å¹¶æ‰“å°æ¨¡å‹çš„æ€»å‚æ•°é‡å’Œå¯è®­ç»ƒå‚æ•°é‡"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print("\n--- æ¨¡å‹å‚æ•°ç»Ÿè®¡ ---")
    print(f"æ€»å‚æ•°é‡ (Total): {total_params / 1e6:.2f} M")
    print(f"å¯è®­ç»ƒå‚æ•°é‡ (Trainable): {trainable_params / 1e6:.2f} M")
    print("----------------------\n")
    return total_params, trainable_params

def write_to_csv(filepath, data_dict, class_names):
    """å°†è¯„ä¼°ç»“æœä»¥è¿½åŠ æ¨¡å¼å†™å…¥æŒ‡å®šçš„CSVæ–‡ä»¶"""
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä»¥å†³å®šæ˜¯å¦éœ€è¦å†™å…¥è¡¨å¤´
    file_exists = os.path.isfile(filepath)
    
    # æ„å»ºCSVçš„è¡¨å¤´ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦è®°å½•çš„ä¿¡æ¯
    header = [
        'checkpoint_path', 'fuse_mode', 'head_type', 'attention_type', 
        'total_params_M', 'trainable_params_M', 
        'mAP', 'f1_micro', 'f1_macro', 'accuracy_micro'
    ]
    # ä¸ºæ¯ä¸ªç±»åˆ«åŠ¨æ€æ·»åŠ APåˆ—
    ap_headers = [f'AP_{name}' for name in class_names]
    header.extend(ap_headers)

    with open(filepath, 'a', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=header)
        
        # å¦‚æœæ–‡ä»¶æ˜¯æ–°å»ºçš„ï¼Œåˆ™å†™å…¥è¡¨å¤´
        if not file_exists:
            writer.writeheader()
            
        # å‡†å¤‡è¦å†™å…¥çš„æ•°æ®è¡Œå­—å…¸
        row_data = {
            'checkpoint_path': data_dict['checkpoint'],
            'fuse_mode': data_dict['train_args'].fuse_mode,
            'head_type': f"{data_dict['train_args'].head_type}_{data_dict['train_args'].attention_type}" if getattr(data_dict['train_args'], 'attention_type', None) else data_dict['train_args'].head_type,
            'attention_type': getattr(data_dict['train_args'], 'attention_type', 'N/A'),
            'total_params_M': f"{data_dict['total_params'] / 1e6:.2f}",
            'trainable_params_M': f"{data_dict['trainable_params'] / 1e6:.2f}",
            'mAP': f"{data_dict['eval_stats'].get('mAP', 0.0):.4f}",
            'f1_micro': f"{data_dict['eval_stats'].get('f1_micro', 0.0):.4f}",
            'f1_macro': f"{data_dict['eval_stats'].get('f1_macro', 0.0):.4f}",
            'accuracy_micro': f"{data_dict['eval_stats'].get('acc1', 0.0):.4f}",
        }
        # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„APå€¼
        if 'per_class_ap' in data_dict['eval_stats'] and len(data_dict['eval_stats']['per_class_ap']) == len(class_names):
            for i, name in enumerate(class_names):
                row_data[f'AP_{name}'] = f"{data_dict['eval_stats']['per_class_ap'][i]:.4f}"
            
        writer.writerow(row_data)
    print(f"\nâœ… è¯„ä¼°ç»“æœå·²æˆåŠŸè¿½åŠ åˆ°: {filepath}")

def main():
    parser = argparse.ArgumentParser(description="è¯„ä¼°ä¸€ä¸ªè®­ç»ƒå¥½çš„åŒè§†è§’æ¨¡å‹")
    parser.add_argument('--checkpoint', type=str, required=True, help='æŒ‡å‘æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶çš„è·¯å¾„ (.pth)')
    parser.add_argument('--val_list', type=str, default=None, help='(å¯é€‰) æŒ‡å‘éªŒè¯é›†æ–‡ä»¶åˆ—è¡¨çš„è·¯å¾„ã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨æ¨¡å‹è®­ç»ƒæ—¶çš„è·¯å¾„ã€‚')
    parser.add_argument('--batch_size', type=int, default=16, help='è¯„ä¼°æ—¶ä½¿ç”¨çš„æ‰¹é‡å¤§å°ã€‚')
    parser.add_argument('--num_workers', type=int, default=8, help='æ•°æ®åŠ è½½ä½¿ç”¨çš„å·¥ä½œçº¿ç¨‹æ•°ã€‚')
    parser.add_argument('--device', type=str, default='cuda', help='è¯„ä¼°è®¾å¤‡ (cuda æˆ– cpu)ã€‚')
    parser.add_argument('--output_csv', type=str, default=None, help='(å¯é€‰) æŒ‡å®šä¸€ä¸ªCSVæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºä¿å­˜è¯„ä¼°ç»“æœã€‚')
    
    cli_args = parser.parse_args()

    # --- 1. åŠ è½½æ£€æŸ¥ç‚¹å’Œé…ç½® ---
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹: {cli_args.checkpoint}")
    if not Path(cli_args.checkpoint).is_file():
        print(f"âŒ é”™è¯¯: æ£€æŸ¥ç‚¹æ–‡ä»¶æœªæ‰¾åˆ° at {cli_args.checkpoint}")
        return

    checkpoint = torch.load(cli_args.checkpoint, map_location='cpu')
    
    if 'args' not in checkpoint:
        print("âŒ é”™è¯¯: æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸­ç¼ºå°‘ 'args' ä¿¡æ¯ï¼Œæ— æ³•è‡ªåŠ¨æ„å»ºæ¨¡å‹ã€‚")
        return
        
    # å°†å­—å…¸è½¬æ¢ä¸º Namespace å¯¹è±¡ï¼Œä½¿å…¶å¯ä»¥åƒ args ä¸€æ ·é€šè¿‡ç‚¹å·è®¿é—®
    train_args = argparse.Namespace(**checkpoint['args'])
    
    # å…¼å®¹æ—§çš„æ£€æŸ¥ç‚¹ï¼Œå¦‚æœ attention_type ä¸å­˜åœ¨ï¼Œåˆ™è®¾ä¸º None
    if not hasattr(train_args, 'attention_type'):
        train_args.attention_type = None

    print("\nâœ… æˆåŠŸä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒé…ç½®:")
    print(f"  - èåˆæ¨¡å¼ (Fuse Mode): {train_args.fuse_mode}")
    print(f"  - å¤´éƒ¨ç±»å‹ (Head Type): {train_args.head_type}")
    print(f"  - æ³¨æ„åŠ›ç±»å‹ (Attention): {train_args.attention_type or 'N/A'}")
    
    # å…è®¸å‘½ä»¤è¡Œå‚æ•°è¦†ç›–éƒ¨åˆ†ä»æ£€æŸ¥ç‚¹ä¸­æ¢å¤çš„é…ç½®
    train_args.val_list = cli_args.val_list if cli_args.val_list else train_args.val_list
    train_args.batch_size = cli_args.batch_size
    train_args.num_workers = cli_args.num_workers
    
    device = torch.device(cli_args.device)

    # --- 2. æ„å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡ ---
    print("\nğŸ—ï¸ æ­£åœ¨æ ¹æ®é…ç½®æ„å»ºæ¨¡å‹...")
    model = build_model(train_args).to(device)
    
    # ä¼˜å…ˆåŠ è½½ EMA (æ•™å¸ˆæ¨¡å‹) æƒé‡è¿›è¡Œè¯„ä¼°ï¼Œè¿™é€šå¸¸æ˜¯æ€§èƒ½æœ€å¥½çš„ç‰ˆæœ¬
    if 'model_ema' in checkpoint:
        print("âœ¨ æ£€æµ‹åˆ° EMA æƒé‡ï¼Œæ­£åœ¨åŠ è½½ EMA çŠ¶æ€è¿›è¡Œè¯„ä¼°...")
        ema_model = SimpleEMA(model, device='cpu')
        ema_model.ema_state = checkpoint['model_ema']
        ema_model.copy_to(model)
    else:
        print("æ­£åœ¨åŠ è½½æ ‡å‡†æ¨¡å‹æƒé‡...")
        model.load_state_dict(checkpoint['model'])
    
    model.eval()

    # --- 3. è®¡ç®—å¹¶æ‰“å°å‚æ•°é‡ ---
    total_params, trainable_params = count_parameters(model)

    # --- 4. å‡†å¤‡éªŒè¯æ•°æ®é›† ---
    print("ğŸ“¦ æ­£åœ¨å‡†å¤‡éªŒè¯æ•°æ®é›†...")
    try:
        _, data_loader_val, class_names = build_loaders(train_args)
        print(f"  - éªŒè¯é›†æ ·æœ¬æ•°: {len(data_loader_val.dataset)}")
        print(f"  - ç±»åˆ«æ•°: {len(class_names)}")
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
        return

    # --- 5. è¿è¡Œè¯„ä¼° ---
    print("\nğŸš€ å¼€å§‹åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼°...")
    
    with torch.no_grad():
        eval_stats = evaluate(
            data_loader=data_loader_val,
            model=model,
            device=device,
            amp=True, # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦åŠ é€Ÿè¯„ä¼°
            threshold=train_args.eval_threshold,
            class_names=class_names,
            csv_path=None # è¯„ä¼°æ—¶ä¸å†™å…¥æ¯ä¸ªepochçš„csv
        )

    # --- 6. æ‰“å°æœ€ç»ˆçš„è¯„ä¼°æŠ¥å‘Š ---
    print("\n--- æœ€ç»ˆè¯„ä¼°æŠ¥å‘Š ---")
    print(f"æ¨¡å‹æ£€æŸ¥ç‚¹: {Path(cli_args.checkpoint).name}")
    print("----------------------")
    print(f"ğŸ“ˆ mAP (mean Average Precision): {eval_stats.get('mAP', 0.0):.4f}")
    print(f"ğŸ“ˆ F1-Score (Micro): {eval_stats.get('f1_micro', 0.0):.4f}")
    print(f"ğŸ“ˆ F1-Score (Macro): {eval_stats.get('f1_macro', 0.0):.4f}")
    print(f"ğŸ“ˆ å‡†ç¡®ç‡ (Micro Accuracy): {eval_stats.get('acc1', 0.0):.4f}")
    print("----------------------")
    # Per-class AP å·²ç»åœ¨ evaluate å‡½æ•°å†…éƒ¨æ‰“å°è¿‡äº†ï¼Œè¿™é‡Œä¸å†é‡å¤

    # --- 7. (æ–°å¢) å¦‚æœæŒ‡å®šäº†CSVæ–‡ä»¶ï¼Œåˆ™å†™å…¥ç»“æœ ---
    if cli_args.output_csv:
        data_to_save = {
            "checkpoint": cli_args.checkpoint,
            "train_args": train_args,
            "total_params": total_params,
            "trainable_params": trainable_params,
            "eval_stats": eval_stats,
        }
        write_to_csv(cli_args.output_csv, data_to_save, class_names)

if __name__ == '__main__':
    main()