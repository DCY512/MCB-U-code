#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ConvNeXtV2 æƒé‡æ˜ å°„è„šæœ¬ v3.1 (æœ€ç»ˆä¿®æ­£ç‰ˆ)
- ä¸“é—¨é€‚é…å®˜æ–¹å‘å¸ƒçš„ PyTorch æƒé‡ (.pt/.pth)
- ä¿®æ­£ GRN å‚æ•°å½¢çŠ¶
- æ·»åŠ  'backbone.' å‰ç¼€
- è¾“å‡ºä¸º safetensors
- [FIX] ç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨ä¿å­˜å‰éƒ½æ˜¯ contiguous çš„
"""
from __future__ import annotations
import argparse
from pathlib import Path
from typing import Dict
import torch

try:
    from safetensors.torch import save_file as safetensors_save
except ImportError:
    raise RuntimeError("è¯·å…ˆå®‰è£… safetensors: pip install safetensors")

def map_key(k: str) -> str:
    """
    å¯¹å®˜æ–¹å‘å¸ƒçš„ ConvNeXtV2 æƒé‡é”®åè¿›è¡Œæœ€å°å¿…è¦è½¬æ¢ã€‚
    å®˜æ–¹é”®åä¸æœ¬é¡¹ç›®æ¨¡å‹ç»“æ„é«˜åº¦ç›¸ä¼¼ï¼Œåªéœ€å¤„ç† DDP å‰ç¼€å’Œæœ€ç»ˆåˆ†ç±»å¤´ã€‚
    """
    nk = k
    if nk.startswith("module."):
        nk = nk[len("module."):]
    
    if nk.startswith("head.norm."):
        nk = nk.replace("head.norm.", "norm.", 1)
    if nk.startswith("head.fc."):
        nk = nk.replace("head.fc.", "head.", 1)
            
    return nk

def reshape_grn_if_needed(k: str, v: torch.Tensor) -> torch.Tensor:
    """
    å®˜æ–¹æƒé‡çš„ GRN gamma/beta æ˜¯ä¸€ç»´çš„ï¼Œéœ€è¦ reshape æˆ (1, 1, 1, C)
    ä»¥åŒ¹é… timm.layers.GRN çš„å®ç°ã€‚
    """
    if (".grn.gamma" in k or ".grn.beta" in k) and v.ndim == 1:
        return v.view(1, 1, 1, -1) # .contiguous() will be called later
    return v

def load_state_dict_from_pt(path: Path) -> Dict[str, torch.Tensor]:
    """ä» .pt æˆ– .pth æ–‡ä»¶åŠ è½½ state_dictã€‚"""
    obj = torch.load(str(path), map_location="cpu")
    if isinstance(obj, dict) and "model" in obj:
        return obj["model"]
    elif isinstance(obj, dict):
        return obj
    else:
        raise RuntimeError(f"ä¸æ”¯æŒçš„ ckpt å¯¹è±¡ç±»å‹ï¼š{type(obj)}")

def main():
    parser = argparse.ArgumentParser(description="å°†å®˜æ–¹ ConvNeXtV2 PyTorch æƒé‡æ˜ å°„ä¸ºé¡¹ç›®å…¼å®¹æ ¼å¼ã€‚")
    parser.add_argument("--input", required=True, type=str, help="è¾“å…¥çš„ .pt æˆ– .pth æƒé‡æ–‡ä»¶è·¯å¾„ã€‚")
    parser.add_argument("--output", required=True, type=str, help="è¾“å‡ºçš„ .safetensors æ–‡ä»¶è·¯å¾„ã€‚")
    parser.add_argument("--add_prefix", default="backbone.", type=str, help="ä¸ºæ‰€æœ‰é”®åæ·»åŠ çš„ç»Ÿä¸€å‰ç¼€ (ä¾‹å¦‚ 'backbone.')ã€‚è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸² '' åˆ™ä¸æ·»åŠ ã€‚")
    args = parser.parse_args()

    src_path = Path(args.input)
    dst_path = Path(args.output)
    dst_path.parent.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ“„ æ­£åœ¨è¯»å–æºæƒé‡: {src_path}")

    sd_in = load_state_dict_from_pt(src_path)
    blacklist = ['head.']
    sd_filtered = {}
    for k, v in sd_in.items():
        # æ£€æŸ¥å½“å‰å‚æ•°çš„åç§°æ˜¯å¦ä»¥é»‘åå•ä¸­çš„ä»»ä½•å‰ç¼€å¼€å¤´
        is_blacklisted = any(k.startswith(prefix) for prefix in blacklist)
        if not is_blacklisted:
            sd_filtered[k] = v
    
    print(f"âœ… æƒé‡è¿‡æ»¤å®Œæˆ: åŸå§‹ {len(sd_in)} -> è¿‡æ»¤å {len(sd_filtered)} (ä¸¢å¼ƒäº† {len(sd_in) - len(sd_filtered)} ä¸ª head å‚æ•°)")
    sd_out: Dict[str, torch.Tensor] = {}

    mapped_count = 0
    grn_reshaped_count = 0

    for key, value in sd_filtered.items():
        new_key = map_key(key)
        
        final_value = reshape_grn_if_needed(new_key, value)
        if final_value is not value:
            grn_reshaped_count += 1
        
        if args.add_prefix:
            final_key = args.add_prefix + new_key
        else:
            final_key = new_key
            
        # ==================== FIX ====================
        # ç¡®ä¿å¼ é‡åœ¨ä¿å­˜å‰æ˜¯ contiguous çš„ï¼Œä»¥æ»¡è¶³ safetensors çš„è¦æ±‚
        sd_out[final_key] = final_value.contiguous()
        # =============================================
        
        mapped_count += 1

    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ {len(sd_out)} ä¸ªæƒé‡åˆ°: {dst_path}")
    safetensors_save(sd_out, str(dst_path))
    
    print("\nâœ… è½¬æ¢å®Œæˆ!")
    print(f"  - æ€»å…±å¤„ç†: {mapped_count} ä¸ªæƒé‡ã€‚")
    print(f"  - GRN å‚æ•°å½¢çŠ¶ä¿®æ­£: {grn_reshaped_count} ä¸ªã€‚")
    print(f"  - æ·»åŠ çš„å‰ç¼€: '{args.add_prefix}'")

if __name__ == "__main__":
    main()